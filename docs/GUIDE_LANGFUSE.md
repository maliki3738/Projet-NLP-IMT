# üìä Configuration Langfuse - Observabilit√© LLM

> Plateforme d'observabilit√© pour tracer les appels LLM, monitorer les co√ªts et analyser les performances.

---

## Cr√©ation Compte (2 minutes)

1. Aller sur https://cloud.langfuse.com
2. **Sign Up** avec email/GitHub/Google
3. Confirmer l'email
4. Cr√©er un projet : `imt-agent`

**Plan gratuit** : 50 000 √©v√©nements/mois

---

## R√©cup√©ration Cl√©s API (1 minute)

1. Dashboard Langfuse ‚Üí **Settings** ‚öôÔ∏è ‚Üí **API Keys**
2. **Create new API key**
3. Copier les 2 cl√©s :
   - `LANGFUSE_PUBLIC_KEY` (pk-lf-...)
   - `LANGFUSE_SECRET_KEY` (sk-lf-...)

‚ö†Ô∏è La cl√© secr√®te ne s'affiche qu'une fois !

---

## Configuration `.env`

```env
# Langfuse Observability
LANGFUSE_PUBLIC_KEY=pk-lf-xxxxxxxxxxxxxxxxxxxxxxxx
LANGFUSE_SECRET_KEY=sk-lf-xxxxxxxxxxxxxxxxxxxxxxxx
LANGFUSE_HOST=https://cloud.langfuse.com
```

---

## Test

```bash
# Red√©marrer Chainlit
chainlit run chainlit_app.py

# V√©rifier logs
# ‚úÖ "Langfuse configur√© avec succ√®s"
# au lieu de ‚ö†Ô∏è "Langfuse non disponible"
```

---

## Dashboard Langfuse

**Acc√®s** : https://cloud.langfuse.com ‚Üí Projet `imt-agent`

### Onglets Disponibles

| Onglet | Information |
|--------|-------------|
| **Traces** | Tous les appels LLM en temps r√©el |
| **Analytics** | Statistiques tokens, co√ªts, latences |
| **Prompts** | Historique des prompts utilis√©s |
| **Users** | Sessions utilisateurs |

### Exemple de Trace

```json
{
  "model": "gemini-2.5-flash",
  "tokens_input": 125,
  "tokens_output": 89,
  "cost_usd": 0.0,
  "latency_ms": 1200,
  "status": "success"
}
```

---

## Donn√©es Track√©es

```python
# Code dans app/agent.py
langfuse_client.create_event(
    name="gemini_response",
    metadata={
        "model": "gemini-2.5-flash",
        "tokens_input": input_tokens,
        "tokens_output": output_tokens,
        "cost_usd": 0.0  # Gemini gratuit
    },
    input=prompt[:500],
    output=result[:500]
)
```

**Metrics** :
- Tokens input/output
- Co√ªts USD (Grok, OpenAI)
- Latence (ms)
- Taux d'erreur

---

## D√©pannage

| Probl√®me | Solution |
|----------|----------|
| Cl√©s invalides | V√©rifier copi√©/coll√© sans espaces |
| Pas de traces | Red√©marrer app apr√®s config .env |
| Dashboard vide | Tester avec `python test_agent_rag.py` |

---

**Documentation** : [app/agent.py](../app/agent.py) (lignes 340-360)
- Co√ªts par mod√®le
- Latences moyennes
- Tokens utilis√©s par jour
- Taux d'erreur

### Prompts
- G√©rer les versions de prompts
- Comparer les performances
- A/B testing

## ‚úÖ Validation finale

Checklist de v√©rification :

- [ ] Compte Langfuse cr√©√©
- [ ] Cl√©s API dans `.env`
- [ ] Agent red√©marr√©
- [ ] Logs affichent "‚úÖ Langfuse configur√©"
- [ ] Dashboard affiche les traces
- [ ] Screenshot pris pour documentation

## üêõ D√©pannage

### Erreur : "Authentication error"
- V√©rifier que les cl√©s sont bien copi√©es (pas d'espaces)
- V√©rifier que `LANGFUSE_PUBLIC_KEY` commence par `pk-lf-`
- V√©rifier que `LANGFUSE_SECRET_KEY` commence par `sk-lf-`

### Erreur : "No traces in dashboard"
- Attendre 10-30 secondes (d√©lai d'envoi)
- V√©rifier que l'agent a bien √©t√© appel√© (faire une question)
- V√©rifier la connexion internet

### Erreur : "Module not found: langfuse"
```bash
source venv/bin/activate
pip install langfuse
```

## üìù Code int√©gr√© (r√©f√©rence)

Le code suivant est d√©j√† dans `app/agent.py` :

```python
# Langfuse initialization
try:
    from langfuse import Langfuse
    langfuse_client = Langfuse(
        public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
        secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
        host=os.getenv("LANGFUSE_HOST", "https://cloud.langfuse.com")
    )
    LANGFUSE_AVAILABLE = True
    logger.info("‚úÖ Langfuse configur√© avec succ√®s")
except Exception as e:
    langfuse_client = None
    LANGFUSE_AVAILABLE = False
    logger.warning(f"‚ö†Ô∏è Langfuse non disponible : {e}")
```

Chaque appel LLM envoie une trace :

```python
if LANGFUSE_AVAILABLE:
    trace = langfuse_client.trace(
        name="gemini_call",
        user_id=session_id,
        metadata={"model": "gemini-pro", "query": query}
    )
```

## üîó Ressources

- Documentation Langfuse : https://langfuse.com/docs
- Pricing : https://langfuse.com/pricing (gratuit jusqu'√† 50k events)
- Support : support@langfuse.com

## üéâ F√©licitations !

Langfuse est maintenant actif ! Vous pouvez :
- Monitorer toutes les conversations en temps r√©el
- Analyser les performances des mod√®les
- Optimiser les co√ªts
- D√©boguer les probl√®mes efficacement

---

**Prochaine √©tape** : Customiser l'UI Chainlit (logo, couleurs) ‚Üí Voir `GUIDE_CHAINLIT.md`
