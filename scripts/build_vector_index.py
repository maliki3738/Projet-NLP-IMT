# scripts/build_vector_index.py
"""
Construit un index vectoriel FAISS √† partir des chunks de texte.
Utilise Sentence-Transformers pour g√©n√©rer des embeddings s√©mantiques.
"""
from pathlib import Path
import json
import pickle
import numpy as np
from sentence_transformers import SentenceTransformer

DATA_DIR = Path("data")
CHUNKS_FILE = DATA_DIR / "chunks.json"
EMBEDDINGS_FILE = DATA_DIR / "embeddings.pkl"
INDEX_FILE = DATA_DIR / "faiss_index.pkl"

def build_vector_index():
    """Cr√©e l'index vectoriel FAISS √† partir des chunks."""
    
    # 1. Charger les chunks
    print("üìÇ Chargement des chunks...")
    with open(CHUNKS_FILE, 'r', encoding='utf-8') as f:
        chunks = json.load(f)
    
    print(f"‚úÖ {len(chunks)} chunks charg√©s")
    
    # 2. Charger le mod√®le d'embeddings (multilingue fran√ßais)
    print("ü§ñ Chargement du mod√®le Sentence-Transformer...")
    model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
    
    # 3. G√©n√©rer les embeddings
    print("üîÑ G√©n√©ration des embeddings...")
    texts = [chunk['content'] for chunk in chunks]
    embeddings = model.encode(texts, show_progress_bar=True)
    
    # 4. Sauvegarder les embeddings et m√©tadonn√©es
    print("üíæ Sauvegarde de l'index...")
    data = {
        'chunks': chunks,
        'embeddings': embeddings,
        'model_name': 'paraphrase-multilingual-MiniLM-L12-v2'
    }
    
    with open(EMBEDDINGS_FILE, 'wb') as f:
        pickle.dump(data, f)
    
    print(f"‚úÖ Index vectoriel cr√©√© avec succ√®s !")
    print(f"   - {len(chunks)} chunks")
    print(f"   - Dimension embeddings : {embeddings.shape[1]}")
    print(f"   - Fichier : {EMBEDDINGS_FILE}")

if __name__ == "__main__":
    build_vector_index()
