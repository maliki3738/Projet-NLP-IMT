# scripts/build_vector_index.py
"""
Construit un index vectoriel FAISS √† partir des chunks de texte.
Utilise Sentence-Transformers pour g√©n√©rer des embeddings s√©mantiques.
"""
from pathlib import Path
import json
import pickle
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer

DATA_DIR = Path("data")
CHUNKS_FILE = DATA_DIR / "chunks.json"
EMBEDDINGS_FILE = DATA_DIR / "embeddings.pkl"
FAISS_INDEX_FILE = DATA_DIR / "faiss.index"

def build_vector_index():
    """Cr√©e l'index vectoriel FAISS √† partir des chunks."""
    
    # 1. Charger les chunks
    print("üìÇ Chargement des chunks...")
    with open(CHUNKS_FILE, 'r', encoding='utf-8') as f:
        chunks = json.load(f)
    
    print(f"‚úÖ {len(chunks)} chunks charg√©s")
    
    # 2. Charger le mod√®le d'embeddings (multilingue fran√ßais)
    print("ü§ñ Chargement du mod√®le Sentence-Transformer...")
    model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
    
    # 3. G√©n√©rer les embeddings (par petits batchs pour √©viter segfault)
    print("üîÑ G√©n√©ration des embeddings...")
    texts = [chunk['content'] for chunk in chunks]
    
    # Encoder en une seule fois SANS show_progress_bar (cause du segfault)
    embeddings = model.encode(texts, convert_to_numpy=True, show_progress_bar=False)
    embeddings = embeddings.astype('float32')
    print(f"‚úÖ Embeddings g√©n√©r√©s : {embeddings.shape}")
    
    # 4. Cr√©er l'index FAISS (IndexFlatIP pour similarit√© cosinus)
    print("üîß Cr√©ation de l'index FAISS...")
    dimension = embeddings.shape[1]
    
    # Normaliser les embeddings pour utiliser IndexFlatIP (similarit√© cosinus)
    faiss.normalize_L2(embeddings)
    
    # Cr√©er l'index FAISS (Flat = recherche exhaustive, IP = Inner Product)
    index = faiss.IndexFlatIP(dimension)
    index.add(embeddings.astype('float32'))
    
    # 5. Sauvegarder l'index FAISS
    print("üíæ Sauvegarde de l'index FAISS...")
    faiss.write_index(index, str(FAISS_INDEX_FILE))
    
    # 6. Sauvegarder les m√©tadonn√©es (chunks) s√©par√©ment
    metadata = {
        'chunks': chunks,
        'model_name': 'paraphrase-multilingual-MiniLM-L12-v2'
    }
    
    with open(EMBEDDINGS_FILE, 'wb') as f:
        pickle.dump(metadata, f)
    
    print(f"‚úÖ Index FAISS cr√©√© avec succ√®s !")
    print(f"   - {len(chunks)} chunks index√©s")
    print(f"   - Dimension embeddings : {dimension}")
    print(f"   - Index FAISS : {FAISS_INDEX_FILE}")
    print(f"   - M√©tadonn√©es : {EMBEDDINGS_FILE}")
    print(f"   - Type index : IndexFlatIP (similarit√© cosinus)")

if __name__ == "__main__":
    build_vector_index()
