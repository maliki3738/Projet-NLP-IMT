"""
Agent LangChain intelligent pour l'IMT utilisant Gemini avec function calling.

Version compatible LangChain 1.x - Architecture intelligente avec outils.
"""
import os
import logging
from typing import Optional, List, Dict, Any
from dotenv import load_dotenv

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_core.tools import tool

from app.tools import search_imt as _search_imt_original
from app.tools import send_email as _send_email_original

# Configuration
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
load_dotenv()

# D√©finition des outils LangChain
@tool
def search_imt(query: str) -> str:
    """Recherche des informations sur l'IMT (formations, admissions, programmes, contact).
    
    Utilise cette fonction quand l'utilisateur demande :
    - Les formations disponibles
    - Les conditions d'admission
    - Les programmes d'√©tudes
    - Les informations de contact
    - Toute information sur l'IMT
    
    Args:
        query: La question de l'utilisateur sur l'IMT
        
    Returns:
        Les informations trouv√©es dans la base de connaissances
    """
    logger.info(f"üîç Outil search_imt appel√© avec: {query[:50]}...")
    return _search_imt_original(query)

@tool
def send_email(subject: str, content: str, recipient: Optional[str] = None) -> str:
    """Envoie un email de contact √† l'IMT.
    
    Utilise cette fonction quand l'utilisateur veut :
    - Envoyer une demande d'information
    - Contacter l'administration
    - Poser une question n√©cessitant une r√©ponse personnalis√©e
    
    Args:
        subject: Sujet de l'email
        content: Contenu du message
        recipient: Email du destinataire (optionnel)
        
    Returns:
        Confirmation d'envoi ou erreur
    """
    logger.info(f"üìß Outil send_email appel√©: {subject}")
    return _send_email_original(subject, content, recipient)

# Liste des outils disponibles
TOOLS = [search_imt, send_email]

# Prompt syst√®me am√©lior√©
SYSTEM_PROMPT = """Tu es un assistant IA intelligent pour l'IMT (Institut Mines-T√©l√©com) au S√©n√©gal.

Tu as acc√®s √† des outils pour t'aider √† r√©pondre :
- search_imt : Recherche dans la base de connaissances de l'IMT
- send_email : Envoie un email de contact √† l'IMT

CAPACIT√âS DE RAISONNEMENT :
1. Analyse la question pour comprendre l'intention
2. D√©cide SI tu as besoin d'utiliser un outil :
   - Pour des questions sur formations/programmes/admission ‚Üí utilise search_imt
   - Pour des demandes de contact personnalis√© ‚Üí utilise send_email
   - Pour des questions g√©n√©rales/salutations ‚Üí r√©ponds directement
3. Synth√©tise les informations de mani√®re claire et structur√©e

DIRECTIVES :
- R√©ponds TOUJOURS en fran√ßais
- Sois poli, professionnel et serviable
- Raisonne √©tape par √©tape pour les questions complexes
- Si tu utilises un outil, explique pourquoi
- Donne des r√©ponses pr√©cises, compl√®tes et bien format√©es
- Si tu ne sais pas, dis-le honn√™tement et propose d'utiliser search_imt

EXEMPLES DE RAISONNEMENT :
Q: "Quelles formations proposez-vous ?"
‚Üí Je dois chercher dans la base : utiliser search_imt("formations")

Q: "Bonjour, comment allez-vous ?"
‚Üí Salutation simple : r√©pondre directement sans outil

Q: "Je veux m'inscrire en cybers√©curit√©"
‚Üí Besoin d'infos admission : utiliser search_imt("admission cybers√©curit√©")
"""


def create_imt_agent(temperature: float = 0.3, verbose: bool = False):
    """Cr√©e un agent LangChain intelligent avec function calling.
    
    Args:
        temperature: Temp√©rature pour la g√©n√©ration (0.0-1.0)
        verbose: Mode verbeux pour debug
        
    Returns:
        Instance ChatGoogleGenerativeAI avec outils li√©s
        
    Raises:
        ValueError: Si GEMINI_API_KEY manquante
    """
    api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
    if not api_key:
        raise ValueError("GEMINI_API_KEY ou GOOGLE_API_KEY manquante dans .env")
    
    logger.info("‚úÖ Initialisation agent LangChain INTELLIGENT avec Gemini")
    
    # Cr√©er le LLM
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash-exp",
        temperature=temperature,
        google_api_key=api_key,
        verbose=verbose
    )
    
    # Lier les outils au LLM (function calling)
    llm_with_tools = llm.bind_tools(TOOLS)
    
    logger.info(f"üõ†Ô∏è  {len(TOOLS)} outils li√©s : {[t.name for t in TOOLS]}")
    
    return llm_with_tools


def run_agent(question: str, agent: Optional[ChatGoogleGenerativeAI] = None, 
              max_iterations: int = 3) -> str:
    """Ex√©cute l'agent avec raisonnement intelligent et function calling.
    
    L'agent va :
    1. Analyser la question
    2. D√©cider s'il a besoin d'appeler un outil
    3. Appeler l'outil si n√©cessaire
    4. Synth√©tiser une r√©ponse finale
    
    Args:
        question: Question utilisateur
        agent: Agent LLM avec outils (cr√©√© si None)
        max_iterations: Nombre max d'appels d'outils (s√©curit√©)
        
    Returns:
        R√©ponse g√©n√©r√©e intelligemment
    """
    if not question or not question.strip():
        return "Veuillez poser une question valide."
    
    # Cr√©er agent si n√©cessaire
    if agent is None:
        try:
            agent = create_imt_agent()
        except ValueError as e:
            logger.error(f"Erreur cr√©ation agent: {e}")
            return "Agent non disponible (cl√© API manquante)."
    
    try:
        # Historique de la conversation
        messages: List[Any] = [
            SystemMessage(content=SYSTEM_PROMPT),
            HumanMessage(content=question)
        ]
        
        iteration = 0
        
        # Boucle de raisonnement avec outils
        while iteration < max_iterations:
            iteration += 1
            logger.info(f"üß† It√©ration {iteration}: Appel Gemini...")
            
            # Appeler le LLM
            response = agent.invoke(messages)
            
            # V√©rifier si Gemini veut appeler un outil
            tool_calls = getattr(response, 'tool_calls', None) or []
            
            if not tool_calls:
                # Pas d'outil √† appeler ‚Üí r√©ponse finale
                logger.info(f"‚úÖ R√©ponse finale g√©n√©r√©e ({len(response.content)} caract√®res)")
                return response.content.strip()
            
            # Gemini veut appeler des outils
            logger.info(f"üõ†Ô∏è  {len(tool_calls)} outil(s) √† appeler")
            messages.append(response)  # Ajouter la r√©ponse de Gemini
            
            # Ex√©cuter chaque outil demand√©
            for tool_call in tool_calls:
                tool_name = tool_call['name']
                tool_args = tool_call.get('args', {})
                
                logger.info(f"‚öôÔ∏è  Ex√©cution: {tool_name}({tool_args})")
                
                # Trouver et ex√©cuter l'outil
                tool_result = None
                for tool_obj in TOOLS:
                    if tool_obj.name == tool_name:
                        tool_result = tool_obj.invoke(tool_args)
                        break
                
                if tool_result is None:
                    tool_result = f"Erreur: outil '{tool_name}' non trouv√©"
                
                # Ajouter le r√©sultat de l'outil √† l'historique
                from langchain_core.messages import ToolMessage
                messages.append(
                    ToolMessage(
                        content=str(tool_result),
                        tool_call_id=tool_call.get('id', 'unknown')
                    )
                )
                
                logger.info(f"‚úÖ R√©sultat outil: {str(tool_result)[:100]}...")
        
        # Si on sort de la boucle sans r√©ponse finale
        logger.warning(f"‚ö†Ô∏è  Max iterations atteint ({max_iterations})")
        return "D√©sol√©, je n'ai pas pu terminer le traitement de votre question."
        
    except Exception as e:
        logger.error(f"‚ùå Erreur agent: {e}", exc_info=True)
        return f"D√©sol√©, une erreur s'est produite : {str(e)}"


# Fonction wrapper pour compatibilit√©
def create_and_run(question: str) -> str:
    """Cr√©e un agent et ex√©cute une question (usage simple)."""
    return run_agent(question)


if __name__ == "__main__":
    # Test rapide
    print("üß™ Test agent LangChain simplifi√©")
    test_question = "Quelles sont les formations propos√©es √† l'IMT ?"
    response = create_and_run(test_question)
    print(f"\nQuestion: {test_question}")
    print(f"R√©ponse: {response}")